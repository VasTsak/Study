{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y00b5TQZnqs_"
   },
   "source": [
    "# Your First AI application\n",
    "\n",
    "Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications. \n",
    "\n",
    "In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) from Oxford of 102 flower categories, you can see a few examples below. \n",
    "\n",
    "<img src='assets/Flowers.png' width=500px>\n",
    "\n",
    "The project is broken down into multiple steps:\n",
    "\n",
    "* Load the image dataset and create a pipeline.\n",
    "* Build and Train an image classifier on this dataset.\n",
    "* Use your trained model to perform inference on flower images.\n",
    "\n",
    "We'll lead you through each part which you'll implement in Python.\n",
    "\n",
    "When you've completed this project, you'll have an application that can be trained on any set of labeled images. Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKnPjnLAftRV"
   },
   "source": [
    "## Import Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dCk6873paNW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tfds-nightly\n",
      "  Downloading tfds_nightly-3.1.0.dev202005210105-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (1.11.2)\n",
      "Requirement already satisfied: tqdm in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (4.42.1)\n",
      "Requirement already satisfied: numpy in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (1.18.1)\n",
      "Requirement already satisfied: future in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (0.18.2)\n",
      "Requirement already satisfied: dill in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (0.3.1.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (3.12.1)\n",
      "Collecting tensorflow-metadata<0.16,>=0.15\n",
      "  Downloading tensorflow_metadata-0.15.2-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: termcolor in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (1.1.0)\n",
      "Requirement already satisfied: six in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (1.14.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (19.3.0)\n",
      "Requirement already satisfied: absl-py in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (0.9.0)\n",
      "Requirement already satisfied: promise in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tfds-nightly) (2.22.0)\n",
      "Requirement already satisfied: setuptools in /home/vasilis/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tfds-nightly) (45.2.0.post20200210)\n",
      "Requirement already satisfied: googleapis-common-protos in /home/vasilis/anaconda3/lib/python3.7/site-packages (from tensorflow-metadata<0.16,>=0.15->tfds-nightly) (1.51.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/vasilis/anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)\n",
      "Installing collected packages: tensorflow-metadata, tfds-nightly\n",
      "Successfully installed tensorflow-metadata-0.15.2 tfds-nightly-3.1.0.dev202005210105\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# The new version of dataset is only available in the tfds-nightly package.\n",
    "%pip --no-cache-dir install tfds-nightly --user\n",
    "# DON'T MISS TO RESTART THE KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow \n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.2.0\n",
      "\t• tf.keras version: 2.3.0-tf\n",
      "WARNING:tensorflow:From <ipython-input-3-8c0920e1d0b4>:16: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "\t• GPU device not found. Running on CPU\n"
     ]
    }
   ],
   "source": [
    "# TODO: Make all other necessary imports.\n",
    "\n",
    "import warnings\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWKF0YOarpCx"
   },
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Here you'll use `tensorflow_datasets` to load the [Oxford Flowers 102 dataset](https://www.tensorflow.org/datasets/catalog/oxford_flowers102). This dataset has 3 splits: `'train'`, `'test'`, and `'validation'`.  You'll also need to make sure the training data is normalized and resized to 224x224 pixels as required by the pre-trained networks.\n",
    "\n",
    "The validation and testing sets are used to measure the model's performance on data it hasn't seen yet, but you'll still need to normalize and resize the images to the appropriate size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vXISRjfdrrQ6",
    "outputId": "6edf59b2-b468-4c4a-cff4-7cc7cfcc3c2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0522 08:58:10.498774 140175317096256 download_and_prepare.py:201] Running download_and_prepare for dataset(s):\n",
      "oxford_flowers102\n",
      "I0522 08:58:10.772388 140175317096256 dataset_info.py:427] Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: oxford_flowers102/2.1.1\n",
      "I0522 08:58:11.912297 140175317096256 dataset_info.py:358] Load dataset info from /tmp/tmprexmt90ltfds\n",
      "I0522 08:58:11.917723 140175317096256 download_and_prepare.py:139] download_and_prepare for dataset oxford_flowers102/2.1.1...\n",
      "I0522 08:58:11.917936 140175317096256 dataset_builder.py:345] Generating dataset oxford_flowers102 (/home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.1)\n",
      "\u001b[1mDownloading and preparing dataset oxford_flowers102/2.1.1 (download: 328.90 MiB, generated: 331.34 MiB, total: 660.25 MiB) to /home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.1...\u001b[0m\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0522 08:58:12.253362 140175317096256 download_manager.py:477] Downloading https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz into /home/vasilis/tensorflow_datasets/downloads/robots.ox.ac.uk_vgg_flowers_102_102flowersoWedSp98maBn1wypsDib6T-q2NVbO40fwvTflmPmQpY.tgz.tmp.5922446250d44fee92f27a30fdfb09dc...\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0522 08:58:12.257735 140175317096256 download_manager.py:477] Downloading https://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat into /home/vasilis/tensorflow_datasets/downloads/robots.ox.ac.uk_vgg_flowers_102_imagelabelQc558tX8AD-RkJuVyV4EyAI3B3yv3pQFw82vzoHJBkI.mat.tmp.3d4f1a1b302240ab891be4b1b7397c95...\n",
      "Dl Completed...:   0%|                                  | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0522 08:58:12.271087 140175317096256 download_manager.py:477] Downloading https://www.robots.ox.ac.uk/~vgg/data/flowers/102/setid.mat into /home/vasilis/tensorflow_datasets/downloads/robots.ox.ac.uk_vgg_flowers_102_setidSMkjURnWabtzYOtl4t1kAcvHb6vlLbDJOlQsTHUux60.mat.tmp.83e9af0b52f84fa78dbaf891d4b9daa2...\n",
      "Dl Completed...:   0%|                                  | 0/3 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/3 [00:01<?, ? url/s]\n",
      "Dl Size...:   0%|                                     | 0/328 [00:01<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/3 [00:01<?, ? url/s]\n",
      "Dl Size...:   0%|                                     | 0/328 [00:01<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/3 [00:01<?, ? url/s]\n",
      "Dl Size...:   0%|                                     | 0/328 [00:01<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  33%|████████▋                 | 1/3 [00:01<00:03,  1.70s/ url]\n",
      "Dl Size...:   0%|                                     | 0/328 [00:01<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[AI0522 08:58:13.950971 140173591172864 download_manager.py:496] Skipping extraction for /home/vasilis/tensorflow_datasets/downloads/robots.ox.ac.uk_vgg_flowers_102_imagelabelSQPpQga6wjv3cqrfBkUZFt9WtY_Eg6YtsyqXuCZWZR0.mat (method=NO_EXTRACT).\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:01<00:01,  1.70s/ url]\n",
      "Dl Size...:   0%|                                     | 0/328 [00:01<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[AI0522 08:58:13.972501 140173582780160 download_manager.py:496] Skipping extraction for /home/vasilis/tensorflow_datasets/downloads/robots.ox.ac.uk_vgg_flowers_102_setidRrhnj5H9ldPI9P6rgNJxpsg0od2Jb-Kf0-atnOXI3M0.mat (method=NO_EXTRACT).\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:01<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   0%|                             | 1/328 [00:01<10:16,  1.88s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:01<00:01,  1.70s/ url]\n",
      "Dl Size...:   1%|▏                            | 2/328 [00:01<10:14,  1.88s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   1%|▎                            | 3/328 [00:02<07:17,  1.35s/ MiB]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\n",
      "Dl Size...:   1%|▎                            | 4/328 [00:02<07:16,  1.35s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   2%|▍                            | 5/328 [00:02<05:11,  1.04 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\n",
      "Dl Size...:   2%|▌                            | 6/328 [00:02<05:10,  1.04 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   2%|▌                            | 7/328 [00:02<03:41,  1.45 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\n",
      "Dl Size...:   2%|▋                            | 8/328 [00:02<03:40,  1.45 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\n",
      "Dl Size...:   3%|▊                            | 9/328 [00:02<03:40,  1.45 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   3%|▊                           | 10/328 [00:02<02:37,  2.02 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\n",
      "Dl Size...:   3%|▉                           | 11/328 [00:02<02:37,  2.02 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\n",
      "Dl Size...:   4%|█                           | 12/328 [00:02<02:36,  2.02 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   4%|█                           | 13/328 [00:02<01:54,  2.75 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\n",
      "Dl Size...:   4%|█▏                          | 14/328 [00:02<01:54,  2.75 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   5%|█▎                          | 15/328 [00:02<01:31,  3.43 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:02<00:01,  1.70s/ url]\n",
      "Dl Size...:   5%|█▎                          | 16/328 [00:02<01:30,  3.43 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:03<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   5%|█▍                          | 17/328 [00:03<01:15,  4.12 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:03<00:01,  1.70s/ url]\n",
      "Dl Size...:   5%|█▌                          | 18/328 [00:03<01:15,  4.12 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:03<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   6%|█▌                          | 19/328 [00:03<01:04,  4.82 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:03<00:01,  1.70s/ url]\n",
      "Dl Size...:   6%|█▋                          | 20/328 [00:03<01:03,  4.82 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:04<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   6%|█▊                          | 21/328 [00:04<01:14,  4.10 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:04<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   7%|█▉                          | 22/328 [00:04<01:20,  3.82 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:04<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   7%|█▉                          | 23/328 [00:04<01:20,  3.79 MiB/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:04<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   7%|██                          | 24/328 [00:04<01:18,  3.86 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:05<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   8%|██▏                         | 25/328 [00:05<01:16,  3.97 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:05<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   8%|██▏                         | 26/328 [00:05<01:12,  4.15 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:05<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   8%|██▎                         | 27/328 [00:05<01:09,  4.32 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:05<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   9%|██▍                         | 28/328 [00:05<01:06,  4.52 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:05<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   9%|██▍                         | 29/328 [00:05<01:03,  4.69 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:06<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   9%|██▌                         | 30/328 [00:06<01:00,  4.93 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:06<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:   9%|██▋                         | 31/328 [00:06<00:57,  5.13 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:06<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  10%|██▋                         | 32/328 [00:06<00:55,  5.32 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:06<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  10%|██▊                         | 33/328 [00:06<00:53,  5.54 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:06<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  10%|██▉                         | 34/328 [00:06<00:51,  5.70 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:06<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  11%|██▉                         | 35/328 [00:06<00:49,  5.93 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:07<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  11%|███                         | 36/328 [00:07<00:47,  6.14 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:07, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:07<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  11%|███▏                        | 37/328 [00:07<00:45,  6.33 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:07, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:07<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  12%|███▏                        | 38/328 [00:07<00:44,  6.49 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:07, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:07<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  12%|███▎                        | 39/328 [00:07<00:43,  6.66 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:07, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:07<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  12%|███▍                        | 40/328 [00:07<00:41,  6.87 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:07, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:07<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  12%|███▌                        | 41/328 [00:07<00:40,  7.03 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:07, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:07<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  13%|███▌                        | 42/328 [00:07<00:39,  7.21 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:07, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:08<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  13%|███▋                        | 43/328 [00:08<00:38,  7.40 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:08<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  13%|███▊                        | 44/328 [00:08<00:37,  7.57 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:08<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  14%|███▊                        | 45/328 [00:08<00:36,  7.71 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:08<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  14%|███▉                        | 46/328 [00:08<00:36,  7.76 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:08<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  14%|████                        | 47/328 [00:08<00:35,  8.02 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:08<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  15%|████                        | 48/328 [00:08<00:34,  8.15 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:08<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  15%|████▏                       | 49/328 [00:08<00:33,  8.29 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:08<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  15%|████▎                       | 50/328 [00:08<00:33,  8.36 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:08<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  16%|████▎                       | 51/328 [00:08<00:32,  8.59 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:09<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  16%|████▍                       | 52/328 [00:09<00:31,  8.66 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:09, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:09<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  16%|████▌                       | 53/328 [00:09<00:31,  8.87 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:09, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:09<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  16%|████▌                       | 54/328 [00:09<00:30,  8.99 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:09, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:09<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  17%|████▋                       | 55/328 [00:09<00:29,  9.11 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:09, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:09<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  17%|████▊                       | 56/328 [00:09<00:29,  9.27 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:09, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:09<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  17%|████▊                       | 57/328 [00:09<00:28,  9.36 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:09, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:09<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  18%|████▉                       | 58/328 [00:09<00:28,  9.48 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:09, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:09<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  18%|█████                       | 59/328 [00:09<00:28,  9.54 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:09<00:01,  1.70s/ url]\n",
      "Dl Size...:  18%|█████                       | 60/328 [00:09<00:28,  9.54 MiB/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed...: 0 file [00:09, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:09<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  19%|█████▏                      | 61/328 [00:09<00:27,  9.71 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:10<00:01,  1.70s/ url]\n",
      "Dl Size...:  19%|█████▎                      | 62/328 [00:10<00:27,  9.71 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:10, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:10<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  19%|█████▍                      | 63/328 [00:10<00:26,  9.86 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:10<00:01,  1.70s/ url]\n",
      "Dl Size...:  20%|█████▍                      | 64/328 [00:10<00:26,  9.86 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:10, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:10<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  20%|█████▌                      | 65/328 [00:10<00:26, 10.09 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:10<00:01,  1.70s/ url]\n",
      "Dl Size...:  20%|█████▋                      | 66/328 [00:10<00:25, 10.09 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:10, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:10<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  20%|█████▋                      | 67/328 [00:10<00:25, 10.27 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:10<00:01,  1.70s/ url]\n",
      "Dl Size...:  21%|█████▊                      | 68/328 [00:10<00:25, 10.27 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:10, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:10<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  21%|█████▉                      | 69/328 [00:10<00:24, 10.43 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:10<00:01,  1.70s/ url]\n",
      "Dl Size...:  21%|█████▉                      | 70/328 [00:10<00:24, 10.43 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:10, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:10<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  22%|██████                      | 71/328 [00:10<00:24, 10.67 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:11<00:01,  1.70s/ url]\n",
      "Dl Size...:  22%|██████▏                     | 72/328 [00:11<00:23, 10.67 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:11, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:11<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  22%|██████▏                     | 73/328 [00:11<00:23, 10.89 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:11<00:01,  1.70s/ url]\n",
      "Dl Size...:  23%|██████▎                     | 74/328 [00:11<00:23, 10.89 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:11, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:11<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  23%|██████▍                     | 75/328 [00:11<00:24, 10.19 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:11<00:01,  1.70s/ url]\n",
      "Dl Size...:  23%|██████▍                     | 76/328 [00:11<00:24, 10.19 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:11, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:11<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  23%|██████▌                     | 77/328 [00:11<00:29,  8.58 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:11, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:11<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  24%|██████▋                     | 78/328 [00:11<00:32,  7.65 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:11, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:11<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  24%|██████▋                     | 79/328 [00:11<00:34,  7.15 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:11, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:12<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  24%|██████▊                     | 80/328 [00:12<00:35,  6.98 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:12, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:12<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  25%|██████▉                     | 81/328 [00:12<00:35,  6.90 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:12, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:12<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  25%|███████                     | 82/328 [00:12<00:35,  6.88 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:12, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:12<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  25%|███████                     | 83/328 [00:12<00:35,  6.90 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:12, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:12<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  26%|███████▏                    | 84/328 [00:12<00:34,  7.03 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:12, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:12<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  26%|███████▎                    | 85/328 [00:12<00:34,  7.07 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:12, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:12<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  26%|███████▎                    | 86/328 [00:12<00:33,  7.21 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:12, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:13<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  27%|███████▍                    | 87/328 [00:13<00:32,  7.33 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:13, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:13<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  27%|███████▌                    | 88/328 [00:13<00:32,  7.45 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:13, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:13<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  27%|███████▌                    | 89/328 [00:13<00:31,  7.63 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:13, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:13<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  27%|███████▋                    | 90/328 [00:13<00:30,  7.76 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:13, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:13<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  28%|███████▊                    | 91/328 [00:13<00:30,  7.89 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:13, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:13<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  28%|███████▊                    | 92/328 [00:13<00:29,  8.02 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:13, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:13<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  28%|███████▉                    | 93/328 [00:13<00:28,  8.23 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:13, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:13<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  29%|████████                    | 94/328 [00:13<00:27,  8.36 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:13, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:14<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  29%|████████                    | 95/328 [00:14<00:27,  8.43 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:14, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:14<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  29%|████████▏                   | 96/328 [00:14<00:26,  8.62 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:14, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:14<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  30%|████████▎                   | 97/328 [00:14<00:26,  8.73 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:14, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:14<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  30%|████████▎                   | 98/328 [00:14<00:25,  8.86 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:14, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:14<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  30%|████████▍                   | 99/328 [00:14<00:25,  8.94 MiB/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed...: 0 file [00:14, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:14<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  30%|████████▏                  | 100/328 [00:14<00:24,  9.20 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:14, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:14<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  31%|████████▎                  | 101/328 [00:14<00:27,  8.21 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:14, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:14<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  31%|████████▍                  | 102/328 [00:14<00:27,  8.37 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:14, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:15<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  31%|████████▍                  | 103/328 [00:15<00:28,  7.85 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:15, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:15<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  32%|████████▌                  | 104/328 [00:15<00:28,  7.75 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:15, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:15<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  32%|████████▋                  | 105/328 [00:15<00:29,  7.59 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:15, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:15<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  32%|████████▋                  | 106/328 [00:15<00:28,  7.69 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:15, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:15<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  33%|████████▊                  | 107/328 [00:15<00:28,  7.75 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:15, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:15<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  33%|████████▉                  | 108/328 [00:15<00:28,  7.81 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:15, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:15<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  33%|████████▉                  | 109/328 [00:15<00:27,  7.86 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:15, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:15<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  34%|█████████                  | 110/328 [00:15<00:27,  8.02 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:15, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:16<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  34%|█████████▏                 | 111/328 [00:16<00:26,  8.12 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:16, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:16<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  34%|█████████▏                 | 112/328 [00:16<00:26,  8.15 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:16, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:16<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  34%|█████████▎                 | 113/328 [00:16<00:25,  8.29 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:16, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:16<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  35%|█████████▍                 | 114/328 [00:16<00:27,  7.72 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:16, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:16<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  35%|█████████▍                 | 115/328 [00:16<00:29,  7.24 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:16, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:16<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  35%|█████████▌                 | 116/328 [00:16<00:30,  6.91 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:16, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:16<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  36%|█████████▋                 | 117/328 [00:16<00:31,  6.79 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:16, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:17<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  36%|█████████▋                 | 118/328 [00:17<00:30,  6.78 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:17, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:17<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  36%|█████████▊                 | 119/328 [00:17<00:30,  6.82 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:17, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:17<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  37%|█████████▉                 | 120/328 [00:17<00:30,  6.91 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:17, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:17<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  37%|█████████▉                 | 121/328 [00:17<00:29,  7.00 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:17, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:17<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  37%|██████████                 | 122/328 [00:17<00:29,  7.10 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:17, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:17<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  38%|██████████▏                | 123/328 [00:17<00:28,  7.25 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:17, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:17<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  38%|██████████▏                | 124/328 [00:17<00:27,  7.39 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:17, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:17<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  38%|██████████▎                | 125/328 [00:17<00:26,  7.54 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:17, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:18<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  38%|██████████▎                | 126/328 [00:18<00:26,  7.64 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:18, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:18<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  39%|██████████▍                | 127/328 [00:18<00:25,  7.79 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:18, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:18<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  39%|██████████▌                | 128/328 [00:18<00:25,  7.91 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:18, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:18<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  39%|██████████▌                | 129/328 [00:18<00:24,  8.11 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:18, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:18<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  40%|██████████▋                | 130/328 [00:18<00:24,  8.24 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:18, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:18<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  40%|██████████▊                | 131/328 [00:18<00:23,  8.37 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:18, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:18<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  40%|██████████▊                | 132/328 [00:18<00:23,  8.50 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:18, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:18<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  41%|██████████▉                | 133/328 [00:18<00:22,  8.63 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:18, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:19<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  41%|███████████                | 134/328 [00:19<00:21,  8.84 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:19, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:19<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  41%|███████████                | 135/328 [00:19<00:25,  7.69 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:19<00:01,  1.70s/ url]\n",
      "Dl Size...:  41%|███████████▏               | 136/328 [00:19<00:24,  7.69 MiB/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed...: 0 file [00:19, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:19<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  42%|███████████▎               | 137/328 [00:19<00:24,  7.84 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:19, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:19<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  42%|███████████▎               | 138/328 [00:19<00:25,  7.53 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:19, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:19<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  42%|███████████▍               | 139/328 [00:19<00:25,  7.54 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:19, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:19<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  43%|███████████▌               | 140/328 [00:19<00:25,  7.43 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:19, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:19<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  43%|███████████▌               | 141/328 [00:19<00:24,  7.56 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:19, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:20<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  43%|███████████▋               | 142/328 [00:20<00:24,  7.68 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:20, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:20<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  44%|███████████▊               | 143/328 [00:20<00:24,  7.65 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:20, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:20<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  44%|███████████▊               | 144/328 [00:20<00:23,  7.71 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:20, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:20<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  44%|███████████▉               | 145/328 [00:20<00:23,  7.82 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:20, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:20<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  45%|████████████               | 146/328 [00:20<00:22,  7.97 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:20, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:20<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  45%|████████████               | 147/328 [00:20<00:22,  8.20 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:20, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:20<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  45%|████████████▏              | 148/328 [00:20<00:21,  8.27 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:20, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:20<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  45%|████████████▎              | 149/328 [00:20<00:21,  8.32 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:20, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:21<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  46%|████████████▎              | 150/328 [00:21<00:21,  8.36 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:21, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:21<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  46%|████████████▍              | 151/328 [00:21<00:22,  7.84 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:21, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:21<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  46%|████████████▌              | 152/328 [00:21<00:22,  7.70 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:21, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:21<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  47%|████████████▌              | 153/328 [00:21<00:24,  7.25 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:21, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:21<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  47%|████████████▋              | 154/328 [00:21<00:24,  7.03 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:21, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:21<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  47%|████████████▊              | 155/328 [00:21<00:24,  6.95 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:21, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:21<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  48%|████████████▊              | 156/328 [00:21<00:24,  6.92 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:21, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:22<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  48%|████████████▉              | 157/328 [00:22<00:24,  6.96 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:22, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:22<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  48%|█████████████              | 158/328 [00:22<00:23,  7.09 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:22, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:22<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  48%|█████████████              | 159/328 [00:22<00:23,  7.13 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:22, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:22<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  49%|█████████████▏             | 160/328 [00:22<00:23,  7.29 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:22, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:22<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  49%|█████████████▎             | 161/328 [00:22<00:22,  7.47 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:22, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:22<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  49%|█████████████▎             | 162/328 [00:22<00:22,  7.51 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:22, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:22<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  50%|█████████████▍             | 163/328 [00:22<00:21,  7.64 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:22, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:23<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  50%|█████████████▌             | 164/328 [00:23<00:21,  7.79 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:23, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:23<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  50%|█████████████▌             | 165/328 [00:23<00:20,  7.95 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:23, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:23<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  51%|█████████████▋             | 166/328 [00:23<00:19,  8.21 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:23, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:23<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  51%|█████████████▋             | 167/328 [00:23<00:19,  8.26 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:23, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:23<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  51%|█████████████▊             | 168/328 [00:23<00:19,  8.33 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:23, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:23<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  52%|█████████████▉             | 169/328 [00:23<00:18,  8.62 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:23, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:23<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  52%|█████████████▉             | 170/328 [00:23<00:18,  8.61 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:23, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:23<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  52%|██████████████             | 171/328 [00:23<00:17,  8.80 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:23, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:23<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  52%|██████████████▏            | 172/328 [00:23<00:17,  8.85 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:23, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:24<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  53%|██████████████▏            | 173/328 [00:24<00:17,  9.07 MiB/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed...: 0 file [00:24, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:24<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  53%|██████████████▎            | 174/328 [00:24<00:18,  8.34 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:24, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:24<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  53%|██████████████▍            | 175/328 [00:24<00:19,  7.80 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:24, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:24<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  54%|██████████████▍            | 176/328 [00:24<00:20,  7.51 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:24, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:24<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  54%|██████████████▌            | 177/328 [00:24<00:20,  7.50 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:24, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:24<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  54%|██████████████▋            | 178/328 [00:24<00:20,  7.44 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:24, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:24<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  55%|██████████████▋            | 179/328 [00:24<00:19,  7.58 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:24, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:25<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  55%|██████████████▊            | 180/328 [00:25<00:19,  7.70 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:24, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:25<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  55%|██████████████▉            | 181/328 [00:25<00:19,  7.65 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:25, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:25<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  55%|██████████████▉            | 182/328 [00:25<00:18,  7.74 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:25, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:25<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  56%|███████████████            | 183/328 [00:25<00:19,  7.39 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:25, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:25<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  56%|███████████████▏           | 184/328 [00:25<00:21,  6.85 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:25, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:25<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  56%|███████████████▏           | 185/328 [00:25<00:21,  6.75 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:25, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:25<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  57%|███████████████▎           | 186/328 [00:25<00:22,  6.45 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:25, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:26<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  57%|███████████████▍           | 187/328 [00:26<00:21,  6.51 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:26, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:26<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  57%|███████████████▍           | 188/328 [00:26<00:21,  6.53 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:26, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:26<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  58%|███████████████▌           | 189/328 [00:26<00:21,  6.62 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:26, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:26<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  58%|███████████████▋           | 190/328 [00:26<00:20,  6.71 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:26, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:26<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  58%|███████████████▋           | 191/328 [00:26<00:20,  6.76 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:26, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:26<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  59%|███████████████▊           | 192/328 [00:26<00:19,  6.88 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:26, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:26<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  59%|███████████████▉           | 193/328 [00:26<00:19,  7.09 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:26, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:27<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  59%|███████████████▉           | 194/328 [00:27<00:18,  7.27 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:27, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:27<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  59%|████████████████           | 195/328 [00:27<00:18,  7.28 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:27, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:27<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  60%|████████████████▏          | 196/328 [00:27<00:17,  7.51 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:27, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:27<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  60%|████████████████▏          | 197/328 [00:27<00:17,  7.67 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:27, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:27<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  60%|████████████████▎          | 198/328 [00:27<00:16,  7.84 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:27, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:27<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  61%|████████████████▍          | 199/328 [00:27<00:16,  7.95 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:27, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:27<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  61%|████████████████▍          | 200/328 [00:27<00:15,  8.16 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:27, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:27<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  61%|████████████████▌          | 201/328 [00:27<00:15,  8.34 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:27, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:28<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  62%|████████████████▋          | 202/328 [00:28<00:15,  8.37 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:28, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:28<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  62%|████████████████▋          | 203/328 [00:28<00:14,  8.52 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:28, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:28<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  62%|████████████████▊          | 204/328 [00:28<00:14,  8.68 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:28, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:28<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  62%|████████████████▉          | 205/328 [00:28<00:14,  8.76 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:28, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:28<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  63%|████████████████▉          | 206/328 [00:28<00:13,  8.91 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:28, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:28<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  63%|█████████████████          | 207/328 [00:28<00:13,  9.13 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:28, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:28<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  63%|█████████████████          | 208/328 [00:28<00:13,  9.14 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:28, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:28<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  64%|█████████████████▏         | 209/328 [00:28<00:12,  9.27 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:28, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:28<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  64%|█████████████████▎         | 210/328 [00:28<00:12,  9.46 MiB/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed...: 0 file [00:28, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:29<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  64%|█████████████████▎         | 211/328 [00:29<00:14,  7.91 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:29<00:01,  1.70s/ url]\n",
      "Dl Size...:  65%|█████████████████▍         | 212/328 [00:29<00:14,  7.91 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:29, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:29<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  65%|█████████████████▌         | 213/328 [00:29<00:14,  8.17 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:29, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:29<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  65%|█████████████████▌         | 214/328 [00:29<00:14,  7.82 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:29, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:29<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  66%|█████████████████▋         | 215/328 [00:29<00:14,  7.80 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:29, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:29<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  66%|█████████████████▊         | 216/328 [00:29<00:14,  7.88 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:29, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:29<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  66%|█████████████████▊         | 217/328 [00:29<00:17,  6.50 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:29, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:30<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  66%|█████████████████▉         | 218/328 [00:30<00:17,  6.28 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:30, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:30<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  67%|██████████████████         | 219/328 [00:30<00:17,  6.19 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:30, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:30<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  67%|██████████████████         | 220/328 [00:30<00:17,  6.24 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:30, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:30<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  67%|██████████████████▏        | 221/328 [00:30<00:16,  6.34 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:30, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:30<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  68%|██████████████████▎        | 222/328 [00:30<00:16,  6.25 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:30, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:30<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  68%|██████████████████▎        | 223/328 [00:30<00:16,  6.39 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:30, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:30<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  68%|██████████████████▍        | 224/328 [00:30<00:15,  6.53 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:30, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:31<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  69%|██████████████████▌        | 225/328 [00:31<00:15,  6.80 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:31, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:31<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  69%|██████████████████▌        | 226/328 [00:31<00:14,  6.84 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:31, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:31<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  69%|██████████████████▋        | 227/328 [00:31<00:14,  6.96 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:31, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:31<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  70%|██████████████████▊        | 228/328 [00:31<00:13,  7.15 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:31, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:31<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  70%|██████████████████▊        | 229/328 [00:31<00:13,  7.29 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:31, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:31<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  70%|██████████████████▉        | 230/328 [00:31<00:13,  7.41 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:31, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:31<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  70%|███████████████████        | 231/328 [00:31<00:12,  7.55 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:31, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:32<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  71%|███████████████████        | 232/328 [00:32<00:12,  7.70 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:32<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  71%|███████████████████▏       | 233/328 [00:32<00:12,  7.86 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:32<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  71%|███████████████████▎       | 234/328 [00:32<00:11,  8.03 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:32<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  72%|███████████████████▎       | 235/328 [00:32<00:11,  8.27 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:32<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  72%|███████████████████▍       | 236/328 [00:32<00:11,  8.30 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:32<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  72%|███████████████████▌       | 237/328 [00:32<00:10,  8.38 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:32<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  73%|███████████████████▌       | 238/328 [00:32<00:10,  8.66 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:32<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  73%|███████████████████▋       | 239/328 [00:32<00:10,  8.67 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:32<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  73%|███████████████████▊       | 240/328 [00:32<00:09,  8.92 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:33<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  73%|███████████████████▊       | 241/328 [00:33<00:09,  8.95 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:33, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:33<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  74%|███████████████████▉       | 242/328 [00:33<00:09,  9.04 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:33, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:33<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  74%|████████████████████       | 243/328 [00:33<00:09,  9.30 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:33<00:01,  1.70s/ url]\n",
      "Dl Size...:  74%|████████████████████       | 244/328 [00:33<00:09,  9.30 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:33, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:33<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  75%|████████████████████▏      | 245/328 [00:33<00:08,  9.38 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:33<00:01,  1.70s/ url]\n",
      "Dl Size...:  75%|████████████████████▎      | 246/328 [00:33<00:08,  9.38 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:33, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:33<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  75%|████████████████████▎      | 247/328 [00:33<00:08,  9.58 MiB/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed...: 0 file [00:33, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:33<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  76%|████████████████████▍      | 248/328 [00:33<00:09,  8.29 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:33<00:01,  1.70s/ url]\n",
      "Dl Size...:  76%|████████████████████▍      | 249/328 [00:33<00:09,  8.29 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:33, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:34<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  76%|████████████████████▌      | 250/328 [00:34<00:09,  8.54 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:34, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:34<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  77%|████████████████████▋      | 251/328 [00:34<00:09,  8.23 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:34, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:34<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  77%|████████████████████▋      | 252/328 [00:34<00:09,  8.16 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:34, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:34<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  77%|████████████████████▊      | 253/328 [00:34<00:09,  8.08 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:34, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:34<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  77%|████████████████████▉      | 254/328 [00:34<00:13,  5.39 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:34, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:34<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  78%|████████████████████▉      | 255/328 [00:34<00:13,  5.61 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:34, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:35<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  78%|█████████████████████      | 256/328 [00:35<00:12,  5.77 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:35, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:35<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  78%|█████████████████████▏     | 257/328 [00:35<00:12,  5.83 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:35, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:35<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  79%|█████████████████████▏     | 258/328 [00:35<00:11,  6.05 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:35, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:35<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  79%|█████████████████████▎     | 259/328 [00:35<00:11,  6.26 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:35, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:35<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  79%|█████████████████████▍     | 260/328 [00:35<00:10,  6.40 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:35, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:35<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  80%|█████████████████████▍     | 261/328 [00:35<00:10,  6.53 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:35, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:36<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  80%|█████████████████████▌     | 262/328 [00:36<00:09,  6.64 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:36, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:36<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  80%|█████████████████████▋     | 263/328 [00:36<00:09,  6.84 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:36, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:36<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  80%|█████████████████████▋     | 264/328 [00:36<00:09,  7.01 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:36, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:36<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  81%|█████████████████████▊     | 265/328 [00:36<00:08,  7.24 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:36, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:36<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  81%|█████████████████████▉     | 266/328 [00:36<00:08,  7.29 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:36, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:36<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  81%|█████████████████████▉     | 267/328 [00:36<00:08,  7.45 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:36, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:36<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  82%|██████████████████████     | 268/328 [00:36<00:07,  7.65 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:36, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:36<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  82%|██████████████████████▏    | 269/328 [00:36<00:07,  7.81 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:36, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:37<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  82%|██████████████████████▏    | 270/328 [00:37<00:07,  7.94 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:37, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:37<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  83%|██████████████████████▎    | 271/328 [00:37<00:07,  8.04 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:37, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:37<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  83%|██████████████████████▍    | 272/328 [00:37<00:06,  8.09 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:37, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:37<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  83%|██████████████████████▍    | 273/328 [00:37<00:06,  8.50 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:37, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:37<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  84%|██████████████████████▌    | 274/328 [00:37<00:06,  8.44 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:37, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:37<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  84%|██████████████████████▋    | 275/328 [00:37<00:06,  8.77 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:37, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:37<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  84%|██████████████████████▋    | 276/328 [00:37<00:05,  8.73 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:37, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:37<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  84%|██████████████████████▊    | 277/328 [00:37<00:05,  8.98 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:37, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:37<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  85%|██████████████████████▉    | 278/328 [00:37<00:05,  9.05 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:37, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:38<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  85%|██████████████████████▉    | 279/328 [00:38<00:05,  9.13 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:38, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:38<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  85%|███████████████████████    | 280/328 [00:38<00:05,  9.33 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:38, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:38<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  86%|███████████████████████▏   | 281/328 [00:38<00:04,  9.51 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:38<00:01,  1.70s/ url]\n",
      "Dl Size...:  86%|███████████████████████▏   | 282/328 [00:38<00:04,  9.51 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:38, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:38<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  86%|███████████████████████▎   | 283/328 [00:38<00:04,  9.68 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:38, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:38<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  87%|███████████████████████▍   | 284/328 [00:38<00:05,  8.27 MiB/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:38<00:01,  1.70s/ url]\n",
      "Dl Size...:  87%|███████████████████████▍   | 285/328 [00:38<00:05,  8.27 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:38, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:38<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  87%|███████████████████████▌   | 286/328 [00:38<00:04,  8.50 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:38, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:38<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  88%|███████████████████████▋   | 287/328 [00:38<00:04,  8.25 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:38, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:39<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  88%|███████████████████████▋   | 288/328 [00:39<00:04,  8.16 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:39, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:39<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  88%|███████████████████████▊   | 289/328 [00:39<00:04,  8.15 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:39, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:39<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  88%|███████████████████████▊   | 290/328 [00:39<00:04,  8.14 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:39, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:39<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  89%|███████████████████████▉   | 291/328 [00:39<00:04,  8.16 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:39, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:39<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  89%|████████████████████████   | 292/328 [00:39<00:05,  6.18 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:39, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:39<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  89%|████████████████████████   | 293/328 [00:39<00:05,  6.10 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:39, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:40<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  90%|████████████████████████▏  | 294/328 [00:40<00:05,  6.18 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:40, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:40<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  90%|████████████████████████▎  | 295/328 [00:40<00:05,  6.22 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:40, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:40<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  90%|████████████████████████▎  | 296/328 [00:40<00:05,  6.35 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:40, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:40<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  91%|████████████████████████▍  | 297/328 [00:40<00:04,  6.48 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:40, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:40<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  91%|████████████████████████▌  | 298/328 [00:40<00:04,  6.61 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:40, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:40<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  91%|████████████████████████▌  | 299/328 [00:40<00:04,  6.70 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:40, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:40<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  91%|████████████████████████▋  | 300/328 [00:40<00:04,  6.95 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:40, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:41<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  92%|████████████████████████▊  | 301/328 [00:41<00:03,  7.00 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:41, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:41<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  92%|████████████████████████▊  | 302/328 [00:41<00:03,  7.22 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:41, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:41<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  92%|████████████████████████▉  | 303/328 [00:41<00:03,  7.42 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:41, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:41<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  93%|█████████████████████████  | 304/328 [00:41<00:03,  7.55 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:41, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:41<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  93%|█████████████████████████  | 305/328 [00:41<00:03,  7.64 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:41, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:41<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  93%|█████████████████████████▏ | 306/328 [00:41<00:02,  7.79 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:41, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:41<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  94%|█████████████████████████▎ | 307/328 [00:41<00:02,  8.01 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:41, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:41<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  94%|█████████████████████████▎ | 308/328 [00:41<00:02,  8.11 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:41, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:42<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  94%|█████████████████████████▍ | 309/328 [00:42<00:02,  8.27 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:42, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:42<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  95%|█████████████████████████▌ | 310/328 [00:42<00:02,  8.38 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:42, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:42<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  95%|█████████████████████████▌ | 311/328 [00:42<00:01,  8.52 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:42, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:42<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  95%|█████████████████████████▋ | 312/328 [00:42<00:01,  8.64 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:42, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:42<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  95%|█████████████████████████▊ | 313/328 [00:42<00:01,  8.83 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:42, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:42<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  96%|█████████████████████████▊ | 314/328 [00:42<00:01,  8.99 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:42, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:42<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  96%|█████████████████████████▉ | 315/328 [00:42<00:01,  9.02 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:42, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:42<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  96%|██████████████████████████ | 316/328 [00:42<00:01,  9.21 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:42, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:42<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  97%|██████████████████████████ | 317/328 [00:42<00:01,  9.36 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:42, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:42<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  97%|██████████████████████████▏| 318/328 [00:42<00:01,  9.42 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:42, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:43<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  97%|██████████████████████████▎| 319/328 [00:43<00:01,  8.12 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:43, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:43<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  98%|██████████████████████████▎| 320/328 [00:43<00:00,  8.55 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:43, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:43<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  98%|██████████████████████████▍| 321/328 [00:43<00:00,  8.13 MiB/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed...: 0 file [00:43, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:43<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  98%|██████████████████████████▌| 322/328 [00:43<00:00,  7.90 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:43, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:43<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  98%|██████████████████████████▌| 323/328 [00:43<00:00,  7.87 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:43, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:43<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  99%|██████████████████████████▋| 324/328 [00:43<00:00,  7.84 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:43, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:43<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  99%|██████████████████████████▊| 325/328 [00:43<00:00,  7.90 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:43, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:44<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...:  99%|██████████████████████████▊| 326/328 [00:44<00:00,  7.97 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:44, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:44<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...: 100%|██████████████████████████▉| 327/328 [00:44<00:00,  8.05 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:44, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  67%|█████████████████▎        | 2/3 [00:44<00:01,  1.70s/ url]\u001b[A\n",
      "Dl Size...: 100%|███████████████████████████| 328/328 [00:44<00:00,  6.83 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████████████████████| 3/3 [00:44<00:00,  7.61s/ url]\n",
      "Dl Size...: 100%|███████████████████████████| 328/328 [00:44<00:00,  6.83 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████████████████████| 3/3 [00:44<00:00,  7.61s/ url]\n",
      "Dl Size...: 100%|███████████████████████████| 328/328 [00:44<00:00,  6.83 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|                         | 0/1 [00:44<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████████████████████| 3/3 [00:47<00:00,  7.61s/ url]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|███████████████████████████| 328/328 [00:47<00:00,  6.83 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|█████████████████| 1/1 [00:47<00:00, 47.46s/ file]\u001b[A\u001b[A\n",
      "Extraction completed...: 100%|█████████████████| 1/1 [00:47<00:00, 47.46s/ file]\n",
      "\n",
      "Dl Size...: 100%|███████████████████████████| 328/328 [00:47<00:00,  6.91 MiB/s]\n",
      "\n",
      "Dl Completed...: 100%|██████████████████████████| 3/3 [00:47<00:00, 15.82s/ url]\n",
      "I0522 08:58:59.715446 140175317096256 dataset_builder.py:946] Generating split train\n",
      "Shuffling and writing examples to /home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.1.incompleteW8D0JY/oxford_flowers102-train.tfrecord\n",
      "  0%|                                           | 0/1020 [00:00<?, ? examples/s]I0522 08:59:00.051300 140175317096256 tfrecords_writer.py:227] Done writing /home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.1.incompleteW8D0JY/oxford_flowers102-train.tfrecord. Shard lengths: [1020]\n",
      "I0522 08:59:00.051890 140175317096256 dataset_builder.py:946] Generating split test\n",
      "Shuffling and writing examples to /home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.1.incompleteW8D0JY/oxford_flowers102-test.tfrecord\n",
      " 74%|█████████████████████▌       | 4573/6149 [00:00<00:00, 45727.75 examples/s]I0522 08:59:01.827242 140175317096256 tfrecords_writer.py:227] Done writing /home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.1.incompleteW8D0JY/oxford_flowers102-test.tfrecord. Shard lengths: [3074, 3075]\n",
      "I0522 08:59:01.830889 140175317096256 dataset_builder.py:946] Generating split validation\n",
      "Shuffling and writing examples to /home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.1.incompleteW8D0JY/oxford_flowers102-validation.tfrecord\n",
      "  0%|                                           | 0/1020 [00:00<?, ? examples/s]I0522 08:59:02.112593 140175317096256 tfrecords_writer.py:227] Done writing /home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.1.incompleteW8D0JY/oxford_flowers102-validation.tfrecord. Shard lengths: [1020]\n",
      "I0522 08:59:02.113679 140175317096256 dataset_builder.py:400] Skipping computing stats for mode ComputeStatsMode.AUTO.\n",
      "\u001b[1mDataset oxford_flowers102 downloaded and prepared to /home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[1mname: \"oxford_flowers102\"\n",
      "description: \"The Oxford Flowers 102 dataset is a consistent of 102 flower categories commonly occurring\\nin the United Kingdom. Each class consists of between 40 and 258 images. The images have\\nlarge scale, pose and light variations. In addition, there are categories that have large\\nvariations within the category and several very similar categories.\\n\\nThe dataset is divided into a training set, a validation set and a test set.\\nThe training set and validation set each consist of 10 images per class (totalling 1020 images each).\\nThe test set consists of the remaining 6149 images (minimum 20 per class).\"\n",
      "citation: \"@InProceedings{Nilsback08,\\n   author = \\\"Nilsback, M-E. and Zisserman, A.\\\",\\n   title = \\\"Automated Flower Classification over a Large Number of Classes\\\",\\n   booktitle = \\\"Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing\\\",\\n   year = \\\"2008\\\",\\n   month = \\\"Dec\\\"\\n}\"\n",
      "location {\n",
      "  urls: \"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/\"\n",
      "}\n",
      "schema {\n",
      "  feature {\n",
      "    name: \"file_name\"\n",
      "    type: BYTES\n",
      "    domain: \"file_name\"\n",
      "    presence {\n",
      "      min_fraction: 1.0\n",
      "      min_count: 1\n",
      "    }\n",
      "    shape {\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    name: \"image\"\n",
      "    type: BYTES\n",
      "    presence {\n",
      "      min_fraction: 1.0\n",
      "      min_count: 1\n",
      "    }\n",
      "    shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "      dim {\n",
      "        size: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    name: \"label\"\n",
      "    type: INT\n",
      "    presence {\n",
      "      min_fraction: 1.0\n",
      "      min_count: 1\n",
      "    }\n",
      "    shape {\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  string_domain {\n",
      "    name: \"file_name\"\n",
      "    value: \"image_08133.jpg\"\n",
      "    value: \"image_08138.jpg\"\n",
      "    value: \"image_08157.jpg\"\n",
      "    value: \"image_08173.jpg\"\n",
      "    value: \"image_08174.jpg\"\n",
      "    value: \"image_08176.jpg\"\n",
      "    value: \"image_08179.jpg\"\n",
      "    value: \"image_08182.jpg\"\n",
      "    value: \"image_08185.jpg\"\n",
      "    value: \"image_08187.jpg\"\n",
      "  }\n",
      "}\n",
      "splits {\n",
      "  name: \"test\"\n",
      "  statistics {\n",
      "    num_examples: 6149\n",
      "    features {\n",
      "      type: STRING\n",
      "      string_stats {\n",
      "        common_stats {\n",
      "          num_non_missing: 6149\n",
      "          min_num_values: 1\n",
      "          max_num_values: 1\n",
      "          avg_num_values: 1.0\n",
      "          num_values_histogram {\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            type: QUANTILES\n",
      "          }\n",
      "          tot_num_values: 6149\n",
      "        }\n",
      "        unique: 6149\n",
      "        top_values {\n",
      "          value: \"image_08189.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08188.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08186.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08184.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08183.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08181.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08180.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08178.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08172.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08171.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        avg_length: 15.0\n",
      "        rank_histogram {\n",
      "          buckets {\n",
      "            label: \"image_08189.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 1\n",
      "            high_rank: 1\n",
      "            label: \"image_08188.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 2\n",
      "            high_rank: 2\n",
      "            label: \"image_08186.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 3\n",
      "            high_rank: 3\n",
      "            label: \"image_08184.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 4\n",
      "            high_rank: 4\n",
      "            label: \"image_08183.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 5\n",
      "            high_rank: 5\n",
      "            label: \"image_08181.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 6\n",
      "            high_rank: 6\n",
      "            label: \"image_08180.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 7\n",
      "            high_rank: 7\n",
      "            label: \"image_08178.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 8\n",
      "            high_rank: 8\n",
      "            label: \"image_08172.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 9\n",
      "            high_rank: 9\n",
      "            label: \"image_08171.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      path {\n",
      "        step: \"file_name\"\n",
      "      }\n",
      "    }\n",
      "    features {\n",
      "      type: STRING\n",
      "      string_stats {\n",
      "        common_stats {\n",
      "          num_non_missing: 6149\n",
      "          min_num_values: 1\n",
      "          max_num_values: 1\n",
      "          avg_num_values: 1.0\n",
      "          num_values_histogram {\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            type: QUANTILES\n",
      "          }\n",
      "          tot_num_values: 6149\n",
      "        }\n",
      "        unique: 6147\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 2.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 2.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        avg_length: 42333.9453125\n",
      "        rank_histogram {\n",
      "          buckets {\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 2.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 1\n",
      "            high_rank: 1\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 2.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 2\n",
      "            high_rank: 2\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 3\n",
      "            high_rank: 3\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 4\n",
      "            high_rank: 4\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 5\n",
      "            high_rank: 5\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 6\n",
      "            high_rank: 6\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 7\n",
      "            high_rank: 7\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 8\n",
      "            high_rank: 8\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 9\n",
      "            high_rank: 9\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      path {\n",
      "        step: \"image\"\n",
      "      }\n",
      "    }\n",
      "    features {\n",
      "      num_stats {\n",
      "        common_stats {\n",
      "          num_non_missing: 6149\n",
      "          min_num_values: 1\n",
      "          max_num_values: 1\n",
      "          avg_num_values: 1.0\n",
      "          num_values_histogram {\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 614.9\n",
      "            }\n",
      "            type: QUANTILES\n",
      "          }\n",
      "          tot_num_values: 6149\n",
      "        }\n",
      "        mean: 57.81362823223289\n",
      "        std_dev: 26.889661542349568\n",
      "        num_zeros: 20\n",
      "        median: 60.0\n",
      "        max: 101.0\n",
      "        histograms {\n",
      "          buckets {\n",
      "            high_value: 10.1\n",
      "            sample_count: 388.0019\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 10.1\n",
      "            high_value: 20.2\n",
      "            sample_count: 388.00190000000003\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 20.2\n",
      "            high_value: 30.299999999999997\n",
      "            sample_count: 394.1509\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 30.299999999999997\n",
      "            high_value: 40.4\n",
      "            sample_count: 449.4919\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 40.4\n",
      "            high_value: 50.5\n",
      "            sample_count: 855.3258999999999\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 50.5\n",
      "            high_value: 60.599999999999994\n",
      "            sample_count: 621.6638999999999\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 60.599999999999994\n",
      "            high_value: 70.7\n",
      "            sample_count: 418.74690000000004\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 70.7\n",
      "            high_value: 80.8\n",
      "            sample_count: 1187.3719\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 80.8\n",
      "            high_value: 90.89999999999999\n",
      "            sample_count: 812.2829\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 90.89999999999999\n",
      "            high_value: 101.0\n",
      "            sample_count: 633.9619\n",
      "          }\n",
      "        }\n",
      "        histograms {\n",
      "          buckets {\n",
      "            high_value: 16.0\n",
      "            sample_count: 614.9\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 16.0\n",
      "            high_value: 33.0\n",
      "            sample_count: 614.9\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 33.0\n",
      "            high_value: 44.0\n",
      "            sample_count: 614.9\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 44.0\n",
      "            high_value: 50.0\n",
      "            sample_count: 614.9\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 50.0\n",
      "            high_value: 60.0\n",
      "            sample_count: 614.9\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 60.0\n",
      "            high_value: 72.0\n",
      "            sample_count: 614.9\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 72.0\n",
      "            high_value: 76.0\n",
      "            sample_count: 614.9\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 76.0\n",
      "            high_value: 83.0\n",
      "            sample_count: 614.9\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 83.0\n",
      "            high_value: 91.0\n",
      "            sample_count: 614.9\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 91.0\n",
      "            high_value: 101.0\n",
      "            sample_count: 614.9\n",
      "          }\n",
      "          type: QUANTILES\n",
      "        }\n",
      "      }\n",
      "      path {\n",
      "        step: \"label\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  shard_lengths: 3074\n",
      "  shard_lengths: 3075\n",
      "  num_bytes: 260784877\n",
      "}\n",
      "splits {\n",
      "  name: \"train\"\n",
      "  statistics {\n",
      "    num_examples: 1020\n",
      "    features {\n",
      "      type: STRING\n",
      "      string_stats {\n",
      "        common_stats {\n",
      "          num_non_missing: 1020\n",
      "          min_num_values: 1\n",
      "          max_num_values: 1\n",
      "          avg_num_values: 1.0\n",
      "          num_values_histogram {\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            type: QUANTILES\n",
      "          }\n",
      "          tot_num_values: 1020\n",
      "        }\n",
      "        unique: 1020\n",
      "        top_values {\n",
      "          value: \"image_08177.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08175.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08167.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08166.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08165.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08164.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08161.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08154.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08148.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08135.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        avg_length: 15.0\n",
      "        rank_histogram {\n",
      "          buckets {\n",
      "            label: \"image_08177.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 1\n",
      "            high_rank: 1\n",
      "            label: \"image_08175.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 2\n",
      "            high_rank: 2\n",
      "            label: \"image_08167.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 3\n",
      "            high_rank: 3\n",
      "            label: \"image_08166.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 4\n",
      "            high_rank: 4\n",
      "            label: \"image_08165.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 5\n",
      "            high_rank: 5\n",
      "            label: \"image_08164.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 6\n",
      "            high_rank: 6\n",
      "            label: \"image_08161.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 7\n",
      "            high_rank: 7\n",
      "            label: \"image_08154.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 8\n",
      "            high_rank: 8\n",
      "            label: \"image_08148.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 9\n",
      "            high_rank: 9\n",
      "            label: \"image_08135.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      path {\n",
      "        step: \"file_name\"\n",
      "      }\n",
      "    }\n",
      "    features {\n",
      "      type: STRING\n",
      "      string_stats {\n",
      "        common_stats {\n",
      "          num_non_missing: 1020\n",
      "          min_num_values: 1\n",
      "          max_num_values: 1\n",
      "          avg_num_values: 1.0\n",
      "          num_values_histogram {\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            type: QUANTILES\n",
      "          }\n",
      "          tot_num_values: 1020\n",
      "        }\n",
      "        unique: 1020\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        avg_length: 42545.15625\n",
      "        rank_histogram {\n",
      "          buckets {\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 1\n",
      "            high_rank: 1\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 2\n",
      "            high_rank: 2\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 3\n",
      "            high_rank: 3\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 4\n",
      "            high_rank: 4\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 5\n",
      "            high_rank: 5\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 6\n",
      "            high_rank: 6\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 7\n",
      "            high_rank: 7\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 8\n",
      "            high_rank: 8\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 9\n",
      "            high_rank: 9\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      path {\n",
      "        step: \"image\"\n",
      "      }\n",
      "    }\n",
      "    features {\n",
      "      num_stats {\n",
      "        common_stats {\n",
      "          num_non_missing: 1020\n",
      "          min_num_values: 1\n",
      "          max_num_values: 1\n",
      "          avg_num_values: 1.0\n",
      "          num_values_histogram {\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            type: QUANTILES\n",
      "          }\n",
      "          tot_num_values: 1020\n",
      "        }\n",
      "        mean: 50.5\n",
      "        std_dev: 29.443448620476957\n",
      "        num_zeros: 10\n",
      "        median: 51.0\n",
      "        max: 101.0\n",
      "        histograms {\n",
      "          buckets {\n",
      "            high_value: 10.1\n",
      "            sample_count: 109.242\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 10.1\n",
      "            high_value: 20.2\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 20.2\n",
      "            high_value: 30.299999999999997\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 30.299999999999997\n",
      "            high_value: 40.4\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 40.4\n",
      "            high_value: 50.5\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 50.5\n",
      "            high_value: 60.599999999999994\n",
      "            sample_count: 101.08200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 60.599999999999994\n",
      "            high_value: 70.7\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 70.7\n",
      "            high_value: 80.8\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 80.8\n",
      "            high_value: 90.89999999999999\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 90.89999999999999\n",
      "            high_value: 101.0\n",
      "            sample_count: 109.242\n",
      "          }\n",
      "        }\n",
      "        histograms {\n",
      "          buckets {\n",
      "            high_value: 10.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 10.0\n",
      "            high_value: 20.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 20.0\n",
      "            high_value: 30.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 30.0\n",
      "            high_value: 40.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 40.0\n",
      "            high_value: 51.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 51.0\n",
      "            high_value: 61.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 61.0\n",
      "            high_value: 71.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 71.0\n",
      "            high_value: 81.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 81.0\n",
      "            high_value: 91.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 91.0\n",
      "            high_value: 101.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          type: QUANTILES\n",
      "        }\n",
      "      }\n",
      "      path {\n",
      "        step: \"label\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  shard_lengths: 1020\n",
      "  num_bytes: 43474584\n",
      "}\n",
      "splits {\n",
      "  name: \"validation\"\n",
      "  statistics {\n",
      "    num_examples: 1020\n",
      "    features {\n",
      "      type: STRING\n",
      "      string_stats {\n",
      "        common_stats {\n",
      "          num_non_missing: 1020\n",
      "          min_num_values: 1\n",
      "          max_num_values: 1\n",
      "          avg_num_values: 1.0\n",
      "          num_values_histogram {\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            type: QUANTILES\n",
      "          }\n",
      "          tot_num_values: 1020\n",
      "        }\n",
      "        unique: 1020\n",
      "        top_values {\n",
      "          value: \"image_08187.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08185.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08182.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08179.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08176.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08174.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08173.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08157.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08138.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"image_08133.jpg\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        avg_length: 15.0\n",
      "        rank_histogram {\n",
      "          buckets {\n",
      "            label: \"image_08187.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 1\n",
      "            high_rank: 1\n",
      "            label: \"image_08185.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 2\n",
      "            high_rank: 2\n",
      "            label: \"image_08182.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 3\n",
      "            high_rank: 3\n",
      "            label: \"image_08179.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 4\n",
      "            high_rank: 4\n",
      "            label: \"image_08176.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 5\n",
      "            high_rank: 5\n",
      "            label: \"image_08174.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 6\n",
      "            high_rank: 6\n",
      "            label: \"image_08173.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 7\n",
      "            high_rank: 7\n",
      "            label: \"image_08157.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 8\n",
      "            high_rank: 8\n",
      "            label: \"image_08138.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 9\n",
      "            high_rank: 9\n",
      "            label: \"image_08133.jpg\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      path {\n",
      "        step: \"file_name\"\n",
      "      }\n",
      "    }\n",
      "    features {\n",
      "      type: STRING\n",
      "      string_stats {\n",
      "        common_stats {\n",
      "          num_non_missing: 1020\n",
      "          min_num_values: 1\n",
      "          max_num_values: 1\n",
      "          avg_num_values: 1.0\n",
      "          num_values_histogram {\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            type: QUANTILES\n",
      "          }\n",
      "          tot_num_values: 1020\n",
      "        }\n",
      "        unique: 1020\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        top_values {\n",
      "          value: \"__BYTES_VALUE__\"\n",
      "          frequency: 1.0\n",
      "        }\n",
      "        avg_length: 42256.625\n",
      "        rank_histogram {\n",
      "          buckets {\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 1\n",
      "            high_rank: 1\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 2\n",
      "            high_rank: 2\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 3\n",
      "            high_rank: 3\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 4\n",
      "            high_rank: 4\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 5\n",
      "            high_rank: 5\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 6\n",
      "            high_rank: 6\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 7\n",
      "            high_rank: 7\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 8\n",
      "            high_rank: 8\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_rank: 9\n",
      "            high_rank: 9\n",
      "            label: \"__BYTES_VALUE__\"\n",
      "            sample_count: 1.0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      path {\n",
      "        step: \"image\"\n",
      "      }\n",
      "    }\n",
      "    features {\n",
      "      num_stats {\n",
      "        common_stats {\n",
      "          num_non_missing: 1020\n",
      "          min_num_values: 1\n",
      "          max_num_values: 1\n",
      "          avg_num_values: 1.0\n",
      "          num_values_histogram {\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            buckets {\n",
      "              low_value: 1.0\n",
      "              high_value: 1.0\n",
      "              sample_count: 102.0\n",
      "            }\n",
      "            type: QUANTILES\n",
      "          }\n",
      "          tot_num_values: 1020\n",
      "        }\n",
      "        mean: 50.5\n",
      "        std_dev: 29.443448620476957\n",
      "        num_zeros: 10\n",
      "        median: 51.0\n",
      "        max: 101.0\n",
      "        histograms {\n",
      "          buckets {\n",
      "            high_value: 10.1\n",
      "            sample_count: 109.242\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 10.1\n",
      "            high_value: 20.2\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 20.2\n",
      "            high_value: 30.299999999999997\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 30.299999999999997\n",
      "            high_value: 40.4\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 40.4\n",
      "            high_value: 50.5\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 50.5\n",
      "            high_value: 60.599999999999994\n",
      "            sample_count: 101.08200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 60.599999999999994\n",
      "            high_value: 70.7\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 70.7\n",
      "            high_value: 80.8\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 80.8\n",
      "            high_value: 90.89999999999999\n",
      "            sample_count: 100.06200000000001\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 90.89999999999999\n",
      "            high_value: 101.0\n",
      "            sample_count: 109.242\n",
      "          }\n",
      "        }\n",
      "        histograms {\n",
      "          buckets {\n",
      "            high_value: 10.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 10.0\n",
      "            high_value: 20.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 20.0\n",
      "            high_value: 30.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 30.0\n",
      "            high_value: 40.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 40.0\n",
      "            high_value: 51.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 51.0\n",
      "            high_value: 61.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 61.0\n",
      "            high_value: 71.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 71.0\n",
      "            high_value: 81.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 81.0\n",
      "            high_value: 91.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          buckets {\n",
      "            low_value: 91.0\n",
      "            high_value: 101.0\n",
      "            sample_count: 102.0\n",
      "          }\n",
      "          type: QUANTILES\n",
      "        }\n",
      "      }\n",
      "      path {\n",
      "        step: \"label\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  shard_lengths: 1020\n",
      "  num_bytes: 43180278\n",
      "}\n",
      "supervised_keys {\n",
      "  input: \"image\"\n",
      "  output: \"label\"\n",
      "}\n",
      "version: \"2.1.1\"\n",
      "download_size: 344878000\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found a different version of the requested dataset:\n",
      "/home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.1\n",
      "Using /home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset oxford_flowers102/2.1.0 (download: 336.76 MiB, generated: 331.34 MiB, total: 668.11 MiB) to /home/vasilis/tensorflow_datasets/oxford_flowers102/2.1.0...\u001b[0m\n"
     ]
    },
    {
     "ename": "NonMatchingChecksumError",
     "evalue": "Artifact https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz, downloaded to /home/vasilis/tensorflow_datasets/downloads/robots.ox.ac.uk_vgg_flowers_102_102flowersoWedSp98maBn1wypsDib6T-q2NVbO40fwvTflmPmQpY.tgz.tmp.361c5489b5554b09ad40b73aba9fdf01/102flowers.tgz, has wrong checksum. This might indicate:\n * The website may be down (e.g. returned a 503 status code). Please check the url.\n * For Google Drive URLs, try again later as Drive sometimes rejects downloads when too many people access the same URL. See https://github.com/tensorflow/datasets/issues/1482\n * The original datasets files may have been updated. In this case the TFDS dataset builder should be updated to use the new files and checksums. Sorry about that. Please open an issue or send us a PR with a fix.\n * If you're adding a new dataset, don't forget to register the checksums as explained in: https://www.tensorflow.org/datasets/add_dataset#2_run_download_and_prepare_locally\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNonMatchingChecksumError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-72da1af0f5ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# TODO: Load the dataset with TensorFlow Datasets. Hint: use tfds.load()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'oxford_flowers102'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_supervised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# TODO: Create a training set, a validation set and a test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/registered.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    361\u001b[0m           self._download_and_prepare(\n\u001b[1;32m    362\u001b[0m               \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m               download_config=download_config)\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0;31m# NOTE: If modifying the lines below to put additional information in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m    994\u001b[0m     super(GeneratorBasedBuilder, self)._download_and_prepare(\n\u001b[1;32m    995\u001b[0m         \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m     )\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m         prepare_split_kwargs)\n\u001b[1;32m    915\u001b[0m     for split_generator in self._split_generators(\n\u001b[0;32m--> 916\u001b[0;31m         dl_manager, **split_generators_kwargs):\n\u001b[0m\u001b[1;32m    917\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/image_classification/oxford_flowers102.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    107\u001b[0m             extract_method=tfds.download.ExtractMethod.TAR),\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BASE_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"imagelabels.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;34m\"setid\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BASE_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"setid.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     })\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_map_promise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_extract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m_map_promise\u001b[0;34m(map_fn, all_inputs)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;34m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[0mall_promises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Apply the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_wait_on_promise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_promises\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[1;32m    151\u001b[0m     return {\n\u001b[1;32m    152\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     }\n\u001b[1;32m    155\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdict_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/utils/py_utils.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    151\u001b[0m     return {\n\u001b[1;32m    152\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     }\n\u001b[1;32m    155\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdict_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m_wait_on_promise\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_wait_on_promise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/promise/promise.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDEFAULT_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/promise/promise.py\u001b[0m in \u001b[0;36m_target_settled_value\u001b[0;34m(self, _raise)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_raise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# type: (bool) -> Any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settled_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_target_settled_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/promise/promise.py\u001b[0m in \u001b[0;36m_settled_value\u001b[0;34m(self, _raise)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mraise_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fulfillment_handler0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraise_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fulfillment_handler0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/promise/promise.py\u001b[0m in \u001b[0;36mtry_catch\u001b[0;34m(handler, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m# type: (Callable, Any, Any) -> Union[Tuple[Any, None], Tuple[None, Tuple[Exception, Optional[TracebackType]]]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36mcallback\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    304\u001b[0m       \u001b[0mchecksum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       return self._handle_download_result(\n\u001b[0;32m--> 306\u001b[0;31m           resource, download_dir_path, checksum, dl_size)\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_dir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36m_handle_download_result\u001b[0;34m(self, resource, tmp_dir_path, sha256, dl_size)\u001b[0m\n\u001b[1;32m    259\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_sizes_checksums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdl_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msha256\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sizes_checksums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mNonMatchingChecksumError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0mdownload_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_final_dl_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msha256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     resource_lib.write_info_file(resource, download_path, self._dataset_name,\n",
      "\u001b[0;31mNonMatchingChecksumError\u001b[0m: Artifact https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz, downloaded to /home/vasilis/tensorflow_datasets/downloads/robots.ox.ac.uk_vgg_flowers_102_102flowersoWedSp98maBn1wypsDib6T-q2NVbO40fwvTflmPmQpY.tgz.tmp.361c5489b5554b09ad40b73aba9fdf01/102flowers.tgz, has wrong checksum. This might indicate:\n * The website may be down (e.g. returned a 503 status code). Please check the url.\n * For Google Drive URLs, try again later as Drive sometimes rejects downloads when too many people access the same URL. See https://github.com/tensorflow/datasets/issues/1482\n * The original datasets files may have been updated. In this case the TFDS dataset builder should be updated to use the new files and checksums. Sorry about that. Please open an issue or send us a PR with a fix.\n * If you're adding a new dataset, don't forget to register the checksums as explained in: https://www.tensorflow.org/datasets/add_dataset#2_run_download_and_prepare_locally\n"
     ]
    }
   ],
   "source": [
    "# Download data to default local directory \"~/tensorflow_datasets\"\n",
    "!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums=True --datasets=oxford_flowers102\n",
    "\n",
    "# TODO: Load the dataset with TensorFlow Datasets. Hint: use tfds.load()\n",
    "dataset, dataset_info = tfds.load('oxford_flowers102', as_supervised = True, with_info = True)\n",
    "\n",
    "# TODO: Create a training set, a validation set and a test set.\n",
    "training_set, validation_set, test_set = dataset['train'], dataset['validation'], dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5pdQnDbf0-j"
   },
   "source": [
    "## Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "XikJ4X7FUv8v",
    "outputId": "10240009-1148-41ae-8ce0-4025c2f2fa87"
   },
   "outputs": [],
   "source": [
    "# TODO: Get the number of examples in each set from the dataset info.\n",
    "\n",
    "num_training_examples = dataset_info.splits['train'].num_examples\n",
    "num_validation_examples = dataset_info.splits['validation'].num_examples\n",
    "num_test_examples = dataset_info.splits['test'].num_examples\n",
    "\n",
    "# TODO: Get the number of classes in the dataset from the dataset info.\n",
    "num_classes = dataset_info.features[\"label\"].num_classes\n",
    "class_names = dataset_info.features[\"label\"].names\n",
    "\n",
    "print('There are {:,} classes in our dataset'.format(num_classes))\n",
    "\n",
    "shape_images = dataset_info.features['image'].shape\n",
    "\n",
    "print('The images in our dataset have shape:', shape_images)\n",
    "\n",
    "print('\\nThere are {:,} images in the test set'.format(num_test_examples))\n",
    "print('There are {:,} images in the training set'.format(num_training_examples))\n",
    "print('There are {:,} images in the validation set'.format(num_validation_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "CWR9ScCbPI_D",
    "outputId": "fdf01c8d-2db9-4d7c-a566-4db2599fd1ab"
   },
   "outputs": [],
   "source": [
    "# TODO: Print the shape and corresponding label of 3 images in the training set.\n",
    "for image, label in training_set.take(3):\n",
    "    print('The images in the training set have:\\n\\u2022 shape:', image.shape, '\\n\\u2022 label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "DQbnq8htRTnl",
    "outputId": "32a0e1af-2b04-440e-ddb4-835732be3e83"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot 1 image from the training set. \n",
    "for image, label in training_set.take(1):\n",
    "    image = image.numpy().squeeze()\n",
    "    label = label.numpy()\n",
    "\n",
    "plt.imshow(image, cmap= plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print('The label of this image is:', label)\n",
    "print('The class name of this image is:', class_names[label])\n",
    "\n",
    "# Set the title of the plot to the corresponding image label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuh1841cs-j1"
   },
   "source": [
    "### Label Mapping\n",
    "\n",
    "You'll also need to load in a mapping from label to category name. You can find this in the file `label_map.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/3.7/library/json.html). This will give you a dictionary mapping the integer coded labels to the actual names of the flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoVzdO3KsdSk"
   },
   "outputs": [],
   "source": [
    "with open('label_map.json', 'r') as f:\n",
    "    class_names = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "fc6pMUZgEvUo",
    "outputId": "4274fd43-5cee-4523-885f-a18f6f277dd6"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot 1 image from the training set. Set the title \n",
    "# of the plot to the corresponding class name. \n",
    "\n",
    "for image, label in training_set.take(1):\n",
    "    image = image.numpy().squeeze()\n",
    "    label = label.numpy()\n",
    "\n",
    "plt.imshow(image, cmap= plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print('The label of this image is:', label)\n",
    "print('The class name of this image is:', class_names[str(label)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gL7AaqNf-NC"
   },
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "5hNznLbPNZxS",
    "outputId": "7c114910-b75f-4220-cda9-f84426ec2728"
   },
   "outputs": [],
   "source": [
    "# TODO: Create a pipeline for each set.\n",
    "batch_size = 64\n",
    "image_size = 500\n",
    "\n",
    "# it looks like the images need reformatting \n",
    "\n",
    "def format_image(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (image_size, image_size, 3))\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "\n",
    "training_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(batch_size).prefetch(1)\n",
    "validation_batches = validation_set.map(format_image).batch(batch_size).prefetch(1)\n",
    "testing_batches = test_set.map(format_image).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gR9gtRbeXPYx"
   },
   "source": [
    "# Build and Train the Classifier\n",
    "\n",
    "Now that the data is ready, it's time to build and train the classifier. You should use the MobileNet pre-trained model from TensorFlow Hub to get the image features. Build and train a new feed-forward classifier using those features.\n",
    "\n",
    "We're going to leave this part up to you. If you want to talk through it with someone, chat with your fellow students! \n",
    "\n",
    "Refer to the rubric for guidance on successfully completing this section. Things you'll need to do:\n",
    "\n",
    "* Load the MobileNet pre-trained network from TensorFlow Hub.\n",
    "* Define a new, untrained feed-forward network as a classifier.\n",
    "* Train the classifier.\n",
    "* Plot the loss and accuracy values achieved during training for the training and validation set.\n",
    "* Save your trained model as a Keras model. \n",
    "\n",
    "We've left a cell open for you below, but use as many as you need. Our advice is to break the problem up into smaller parts you can run separately. Check that each part is doing what you expect, then move on to the next. You'll likely find that as you work through each part, you'll need to go back and modify your previous code. This is totally normal!\n",
    "\n",
    "When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right.\n",
    "\n",
    "**Note for Workspace users:** One important tip if you're using the workspace to run your code: To avoid having your workspace disconnect during the long-running tasks in this notebook, please read in the earlier page in this lesson called Intro to GPU Workspaces about Keeping Your Session Active. You'll want to include code from the workspace_utils.py module. Also, If your model is over 1 GB when saved as a checkpoint, there might be issues with saving backups in your workspace. If your saved checkpoint is larger than 1 GB (you can open a terminal and check with `ls -lh`), you should reduce the size of your hidden layers and train again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "feature_extractor = hub.KerasLayer(URL, input_shape=shape_images)\n",
    "\n",
    "feature_extractor.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        feature_extractor,\n",
    "        tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zElEHViXLni"
   },
   "outputs": [],
   "source": [
    "# TODO: Build and train your network.\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(training_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "colab_type": "code",
    "id": "VU6sWzx4e7Yb",
    "outputId": "f7b5c7c5-683a-463c-9228-68c4918bdd5b"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the loss and accuracy values achieved during training for the training and validation set.\n",
    "\n",
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range=range(len(training_accuracy))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, training_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, validation_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcTDnyvop3ky"
   },
   "source": [
    "## Testing your Network\n",
    "\n",
    "It's good practice to test your trained network on test data, images the network has never seen either in training or validation. This will give you a good estimate for the model's performance on completely new images. You should be able to reach around 70% accuracy on the test set if the model has been trained well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "79l7-HM1cafO",
    "outputId": "6cf468a4-1e27-4f20-d63a-a8bdd78bcdbe"
   },
   "outputs": [],
   "source": [
    "# TODO: Print the loss and accuracy values achieved on the entire test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLsIDWnuqfkl"
   },
   "source": [
    "## Save the Model\n",
    "\n",
    "Now that your network is trained, save the model so you can load it later for making inference. In the cell below save your model as a Keras model (*i.e.* save it as an HDF5 file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7XOwdOjSptp-"
   },
   "outputs": [],
   "source": [
    "# TODO: Save your trained model as a Keras model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rbeLSRC1rxuj"
   },
   "source": [
    "## Load the Keras Model\n",
    "\n",
    "Load the Keras model you saved above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "3T6Dgc7Nrzds",
    "outputId": "f5d356dc-183f-4cd3-f15d-88ebb4966082"
   },
   "outputs": [],
   "source": [
    "# TODO: Load the Keras model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjucwuFrsyhJ"
   },
   "source": [
    "# Inference for Classification\n",
    "\n",
    "Now you'll write a function that uses your trained network for inference. Write a function called `predict` that takes an image, a model, and then returns the top $K$ most likely class labels along with the probabilities. The function call should look like: \n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model, top_k)\n",
    "```\n",
    "\n",
    "If `top_k=5` the output of the `predict` function should be something like this:\n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model, 5)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```\n",
    "\n",
    "Your `predict` function should use `PIL` to load the image from the given `image_path`. You can use the [Image.open](https://pillow.readthedocs.io/en/latest/reference/Image.html#PIL.Image.open) function to load the images. The `Image.open()` function returns an `Image` object. You can convert this `Image` object to a NumPy array by using the `np.asarray()` function.\n",
    "\n",
    "The `predict` function will also need to handle pre-processing the input image such that it can be used by your model. We recommend you write a separate function called `process_image` that performs the pre-processing. You can then call the `process_image` function from the `predict` function. \n",
    "\n",
    "### Image Pre-processing\n",
    "\n",
    "The `process_image` function should take in an image (in the form of a NumPy array) and return an image in the form of a NumPy array with shape `(224, 224, 3)`.\n",
    "\n",
    "First, you should convert your image into a TensorFlow Tensor and then resize it to the appropriate size using `tf.image.resize`.\n",
    "\n",
    "Second, the pixel values of the input images are typically encoded as integers in the range 0-255, but the model expects the pixel values to be floats in the range 0-1. Therefore, you'll also need to normalize the pixel values. \n",
    "\n",
    "Finally, convert your image back to a NumPy array using the `.numpy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oG7mJ1-5s1qe"
   },
   "outputs": [],
   "source": [
    "# TODO: Create the process_image function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your `process_image` function we have provided 4 images in the `./test_images/` folder:\n",
    "\n",
    "* cautleya_spicata.jpg\n",
    "* hard-leaved_pocket_orchid.jpg\n",
    "* orange_dahlia.jpg\n",
    "* wild_pansy.jpg\n",
    "\n",
    "The code below loads one of the above images using `PIL` and plots the original image alongside the image produced by your `process_image` function. If your `process_image` function works, the plotted image should be the correct size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = './test_images/hard-leaved_pocket_orchid.jpg'\n",
    "im = Image.open(image_path)\n",
    "test_image = np.asarray(im)\n",
    "\n",
    "processed_test_image = process_image(test_image)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(10,10), ncols=2)\n",
    "ax1.imshow(test_image)\n",
    "ax1.set_title('Original Image')\n",
    "ax2.imshow(processed_test_image)\n",
    "ax2.set_title('Processed Image')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you can get images in the correct format, it's time to write the `predict` function for making inference with your model.\n",
    "\n",
    "### Inference\n",
    "\n",
    "Remember, the `predict` function should take an image, a model, and then returns the top $K$ most likely class labels along with the probabilities. The function call should look like: \n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model, top_k)\n",
    "```\n",
    "\n",
    "If `top_k=5` the output of the `predict` function should be something like this:\n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model, 5)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```\n",
    "\n",
    "Your `predict` function should use `PIL` to load the image from the given `image_path`. You can use the [Image.open](https://pillow.readthedocs.io/en/latest/reference/Image.html#PIL.Image.open) function to load the images. The `Image.open()` function returns an `Image` object. You can convert this `Image` object to a NumPy array by using the `np.asarray()` function.\n",
    "\n",
    "**Note:** The image returned by the `process_image` function is a NumPy array with shape `(224, 224, 3)` but the model expects the input images to be of shape `(1, 224, 224, 3)`. This extra dimension represents the batch size. We suggest you use the `np.expand_dims()` function to add the extra dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBnPKFJuGB32"
   },
   "outputs": [],
   "source": [
    "# TODO: Create the predict function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aft8f_n5C7Co"
   },
   "source": [
    "# Sanity Check\n",
    "\n",
    "It's always good to check the predictions made by your model to make sure they are correct. To check your predictions we have provided 4 images in the `./test_images/` folder:\n",
    "\n",
    "* cautleya_spicata.jpg\n",
    "* hard-leaved_pocket_orchid.jpg\n",
    "* orange_dahlia.jpg\n",
    "* wild_pansy.jpg\n",
    "\n",
    "In the cell below use `matplotlib` to plot the input image alongside the probabilities for the top 5 classes predicted by your model. Plot the probabilities as a bar graph. The plot should look like this:\n",
    "\n",
    "<img src='assets/inference_example.png' width=600px>\n",
    "\n",
    "You can convert from the class integer labels to actual flower names using `class_names`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "I_tBH8xGGVxQ",
    "outputId": "ef0fe795-65f3-49c5-fab0-086fac7d409d"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the input image along with the top 5 classes\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project - Image Classifier Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
