{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "\n",
    "![early_stopping_1.png](pics/early_stopping_1.png)\n",
    "\n",
    "![early_stopping_1.png](pics/early_stopping_2.png)\n",
    "\n",
    "![early_stopping_1.png](pics/early_stopping_3.png)\n",
    "\n",
    "## Regularization\n",
    "\n",
    "![regularization-quiz.png](pics/regularization-quiz.png)\n",
    "\n",
    "**Solution**: $10x_1 + 10 x_2$\n",
    "\n",
    "\n",
    "![regularization_1.png](pics/regularization_1.png)\n",
    "\n",
    "### L1 and L2 Regularization\n",
    "\n",
    "![regularization_1.png](pics/regularization_2.png)\n",
    "![regularization_1.png](pics/regularization_3.png)\n",
    "\n",
    "### Drop out\n",
    "\n",
    "![drop_out_1.png](pics/drop_out_1.png)\n",
    "\n",
    "\n",
    "## Random Restart \n",
    "\n",
    "![random_restart_1.png](pics/random_restart_1.png)\n",
    "\n",
    "\n",
    "## Vanishing Gradient \n",
    "\n",
    "![vanishing_gradient](pics/vanishing_gradient.png)\n",
    "\n",
    "How can we avoind Vanishing Gradient? By using another activation function other than sigmoid, for example: \n",
    "\n",
    "![tahn_1.png](pics/tahn_1.png)\n",
    "\n",
    "or \n",
    "\n",
    "![relu_1.png](pics/relu_1.png)\n",
    "\n",
    "\n",
    "![vanishin_gradient_1.png](pics/vanishin_gradient_1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch vs Stochastic Gradient Descent \n",
    "\n",
    "\n",
    "### Batch processing\n",
    "\n",
    "#### Pros \n",
    "\n",
    "You get to change the weights once you have seen all the data points\n",
    "\n",
    "#### Cons\n",
    "\n",
    "* You consume too much ram per iteration if you have too many data points\n",
    "* Takes too much time for an iteration to be completed\n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "\n",
    "Takes a small subset of the data set, runs them through the network, calculate the gradient of error function based on those points and then move one step in that direcion. \n",
    "\n",
    "\n",
    "## Learning Rate Decay\n",
    "\n",
    "As the training happens, we want to decrease the learning rate because the jumps are getting too big. \n",
    "\n",
    "## Momentum \n",
    "\n",
    "![mom](pics/mom.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
